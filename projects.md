---
layout: article
titles:
  en: Projects
  zh-Hans: 项目
key: page-projects
---

# 项目经历

## 研究项目

### 油气藏生成式表征及智能代理 (2024/09-2025/03)
**中科院研究项目成员**

**成果**：一作论文《A Discrete Neural Operator with Adaptive Sampling for Surrogate Modeling of Parametric Transient Darcy Flows in Porous Media》(Under review)

**主要内容**：
1. 提出一种基于算子空间映射的神经网络模型，相比于现有的残差注意力Unet SOTA结构在流体压力场的预测方面相对误差降低24.3%。
2. 训练过程采用的自适应采样训练策略在极度缺乏初始训练样本的条件下，能够在训练过程中生成高质量特征样本，大幅提升模型在全空间上泛化性能与预测准确率（相比于随机采样相对误差降低35%）。

### 油气甜点生成式大模型构建 (2023/11-2024/03)
**中科院研究项目成员**

**成果**：申请一项专利《一种基于数学期望的小样本学习方法》

**主要内容**：
使用次线性期望的原理构建额外的油气生产过程模拟数据集，为大模型训练提供支持。

### 小样本数据的智能代理模型设计 (2023/09-2024/09)
**青岛软控机电公司研究项目成员**

**成果**：提供一套解决橡胶轮胎产业生产过程中的不平衡数据分类问题的解决办法。

**主要内容**：
使用数据重采样与数据合成技术，合成新少数类样本，并结合次线性期望对数据分组，建模逻辑回归的噪声项服从一个最大分布，最后通过模型进行分类，提升了原有模型大约13%的模型分类准确率。

## 实习项目

### 基于LLM的AI运维工具 (2025.06 - 至今)
**华为杭州研究院(云计算) AI工程师**

**成果**：参与了一项基于LLM的AI运维工具的开发与测试。

**主要内容**：
基于MCP协议与Kubernetes框架开发一个Agent工具，该工具能通过对话实现云计算资源的申请与服务部署，还能检查维护计算节点环境，后续使用MCP-Zero优化tools的查询效率。

**主要贡献**：
1. 使用MCP-Zero技术，进行分层查询，解决了传统大模型对于工具的调用过程需要将所有工具描述都添加到上下文的痛点，大幅减少模型上下文开销（实际测试减少20%多，论文中使用的200多个server，3600个工具，测试简单任务能达到98%开销缩减）。
2. 对于复杂运维问题，大模型可能无法独立依靠工具调用解决，为此参与设计了多条工作流文件，用户问题经过意图识别为复杂问题时，会转进特定工作流，解决特定运维任务（例如K8s中Node节点异常问题诊断）。
3. 使用RAG方法将相关技术文档利用Embedding模型将文档转化为向量，存储到向量数据库中，查询时将相似向量对应文本作为上下文传入LLM，增强回答效果。

### 大模型数学问题求解优化 (2024.10 - 2024.11)
**好未来 NLP实习生**

**成果**：实习期间参与构建模型训练所需的思维链（CoT）数据集，设计大模型评估的自动化脚本工具，动手微调了Qwen2-7b模型。

**主要内容**：
大模型在求解复杂数学问题上容易出错，为了解决这个问题需要对模型进行专项微调，让模型学习解决问题的思考过程，而非是问题到答案的直接映射，因此需要使用专门的CoT数据集进行训练。同时负责微调后模型的性能评估脚本构建，以及文档报告撰写。

**实验结果**：
使用2500个数学题目的CoT数据微调后模型输出的正确率提升了9%。

### 生成式模型自适应采样 (2025.03 - 2025.05)
**振华石油成都研究中心 研究助理**

**成果**：实习期间开发了一套基于生成式模型的自适应采样模块，可以用于加速神经网络模型的训练。

**主要内容**：
传统神经网络模型在训练过程中的训练数据均是通过随机采样获得的，自适应采样本质是通过一个生成模型来生成训练所需的高质量样本。

**实验结果**：
在训练相同精度的代理模型情况下，使用自适应采样所需训练数据量比随机采样少1/6；使用相同数量的数据训练的代理模型情况下，自适应采样方法训练的模型预测结果相对误差要比随机采样低20%-35%。

## 开源贡献

*即将更新...*